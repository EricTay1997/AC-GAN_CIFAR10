{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "00xU2U62VJj3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from resnet20 import ResNetCIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YVZ4r4IPVJj6"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Qncw449VJj8",
    "outputId": "def6e925-b1a6-498c-8513-442bb6f22cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CYZbRmtcVJj9"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(110,768),\n",
    "            nn.ReLU())\n",
    "        self.tconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(768, 384, 5, 2),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 192, 5, 2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU())\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 96, 4, 2),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU())\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 4, 1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU())\n",
    "        self.tconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 3, 4, 2),\n",
    "            nn.Tanh())\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tconv1(out[:,:,None,None])\n",
    "        out = self.tconv2(out)\n",
    "        out = self.tconv3(out)\n",
    "        out = self.tconv4(out)\n",
    "        out = self.tconv5(out)\n",
    "        return out\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4Kgq9oOsVJj-"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor = 2)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.activation_noise_sd = 0.1\n",
    "        self.fc = nn.Linear(8*8*512, 11)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self,x):\n",
    "        if x.shape[-1] == 32:\n",
    "            x = self.upsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.conv2(out)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.conv3(out)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.conv4(out)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.conv5(out)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.conv6(out)\n",
    "        out = self.dropout(out + self.activation_noise_sd*torch.rand(out.shape).to(device))\n",
    "        out = self.fc(out.reshape(-1,8*8*512))\n",
    "        return self.sigmoid(out[:,0]), self.softmax(out[:,1:])\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OBbGJygkVJj_"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "generator = Generator()\n",
    "generator = generator.to(device)\n",
    "discriminator = Discriminator()\n",
    "discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gtgFtp7nVJj_"
   },
   "outputs": [],
   "source": [
    "optimizer_d = optim.Adam(discriminator.parameters(), lr = 0.0001, betas = (0.5, 0.999))\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr = 0.0001, betas = (0.5, 0.999))\n",
    "criterion_source = nn.BCELoss()\n",
    "criterion_class = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qByyHx5RqlqO",
    "outputId": "cf77b9be-9835-4e25-fd78-e2cf9bece264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.load_state_dict(torch.load(\"generator100_large.pt\"))\n",
    "discriminator.load_state_dict(torch.load(\"discriminator100_large.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fzZiK9oyl2ak"
   },
   "outputs": [],
   "source": [
    "def reverse_norm_fake_image(img):\n",
    "    return img*0.5 + 0.5\n",
    "\n",
    "def norm_orig_image(img):\n",
    "    return (img - torch.tensor([0.4914, 0.4822, 0.4465])[None,:,None,None])/torch.tensor([0.2023, 0.1994, 0.2010])[None,:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6nZ-PIAl2qi",
    "outputId": "bf6ee59a-5d9a-40ea-9b8c-df563faf943d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNetCIFAR(num_layers=20)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(\"net_before_pruning.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cYjQjEkdl2tU"
   },
   "outputs": [],
   "source": [
    "def calculate_inception_score(preds, splits = 10):\n",
    "    preds = np.exp(preds)\n",
    "    preds /= preds.sum(axis = 1)[:, None]\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        split = preds[i*preds.shape[0]//splits : (i+1)*preds.shape[0]//splits, :]\n",
    "        kl = split*(np.log(split) - np.log(np.mean(split, axis = 0)))\n",
    "        scores.append(np.exp(np.mean(np.sum(kl, 1))))\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9FZNvG2qlqP",
    "outputId": "4eb44680-d6aa-4b81-a174-2ef828fa9e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 58.78% and 0.717.\n",
      "Discriminator class accuracy and loss on real data is 69.16% and -6.889.\n",
      "Discriminator source accuracy and loss on fake data is 59.35% and 0.697.\n",
      "Discriminator class accuracy and loss on fake data is 96.76% and -0.965.\n",
      "Generator source accuracy and loss is 38.91% and 1.006.\n",
      "Generator class accuracy and loss is 96.77% and -0.965.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet Accuracy: 0.4014\n",
      "Inception Score: 4.351474803157898\n",
      "Epoch 101:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 58.77% and 0.709.\n",
      "Discriminator class accuracy and loss on real data is 70.11% and -6.980.\n",
      "Discriminator source accuracy and loss on fake data is 59.09% and 0.693.\n",
      "Discriminator class accuracy and loss on fake data is 96.50% and -0.962.\n",
      "Generator source accuracy and loss is 38.40% and 0.980.\n",
      "Generator class accuracy and loss is 96.61% and -0.963.\n",
      "\n",
      "Resnet Accuracy: 0.5815\n",
      "Inception Score: 4.827753722048572\n",
      "Epoch 102:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 61.13% and 0.672.\n",
      "Discriminator class accuracy and loss on real data is 70.64% and -7.031.\n",
      "Discriminator source accuracy and loss on fake data is 62.31% and 0.652.\n",
      "Discriminator class accuracy and loss on fake data is 97.03% and -0.967.\n",
      "Generator source accuracy and loss is 35.52% and 1.015.\n",
      "Generator class accuracy and loss is 96.91% and -0.966.\n",
      "\n",
      "Resnet Accuracy: 0.5077\n",
      "Inception Score: 4.332628326702652\n",
      "Epoch 103:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 60.51% and 0.677.\n",
      "Discriminator class accuracy and loss on real data is 70.94% and -7.061.\n",
      "Discriminator source accuracy and loss on fake data is 60.24% and 0.672.\n",
      "Discriminator class accuracy and loss on fake data is 95.96% and -0.957.\n",
      "Generator source accuracy and loss is 36.95% and 0.977.\n",
      "Generator class accuracy and loss is 96.03% and -0.957.\n",
      "\n",
      "Resnet Accuracy: 0.5643\n",
      "Inception Score: 5.210308928004059\n",
      "Epoch 104:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 60.51% and 0.675.\n",
      "Discriminator class accuracy and loss on real data is 70.78% and -7.059.\n",
      "Discriminator source accuracy and loss on fake data is 61.27% and 0.661.\n",
      "Discriminator class accuracy and loss on fake data is 96.65% and -0.964.\n",
      "Generator source accuracy and loss is 36.12% and 0.977.\n",
      "Generator class accuracy and loss is 96.70% and -0.964.\n",
      "\n",
      "Resnet Accuracy: 0.5374\n",
      "Inception Score: 4.171955122391413\n",
      "Epoch 105:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 61.34% and 0.662.\n",
      "Discriminator class accuracy and loss on real data is 71.40% and -7.119.\n",
      "Discriminator source accuracy and loss on fake data is 62.15% and 0.651.\n",
      "Discriminator class accuracy and loss on fake data is 96.69% and -0.965.\n",
      "Generator source accuracy and loss is 35.78% and 0.977.\n",
      "Generator class accuracy and loss is 96.74% and -0.965.\n",
      "\n",
      "Resnet Accuracy: 0.6603\n",
      "Inception Score: 5.721183401971379\n",
      "Epoch 106:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 61.31% and 0.661.\n",
      "Discriminator class accuracy and loss on real data is 71.22% and -7.106.\n",
      "Discriminator source accuracy and loss on fake data is 63.11% and 0.644.\n",
      "Discriminator class accuracy and loss on fake data is 96.40% and -0.961.\n",
      "Generator source accuracy and loss is 34.31% and 0.997.\n",
      "Generator class accuracy and loss is 96.53% and -0.963.\n",
      "\n",
      "Resnet Accuracy: 0.619\n",
      "Inception Score: 4.507441482525021\n",
      "Epoch 107:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 61.31% and 0.663.\n",
      "Discriminator class accuracy and loss on real data is 71.69% and -7.145.\n",
      "Discriminator source accuracy and loss on fake data is 62.24% and 0.648.\n",
      "Discriminator class accuracy and loss on fake data is 97.13% and -0.969.\n",
      "Generator source accuracy and loss is 34.36% and 0.987.\n",
      "Generator class accuracy and loss is 97.05% and -0.968.\n",
      "\n",
      "Resnet Accuracy: 0.6771\n",
      "Inception Score: 5.008049301206733\n",
      "Epoch 108:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.04% and 0.655.\n",
      "Discriminator class accuracy and loss on real data is 71.95% and -7.160.\n",
      "Discriminator source accuracy and loss on fake data is 62.72% and 0.644.\n",
      "Discriminator class accuracy and loss on fake data is 97.60% and -0.974.\n",
      "Generator source accuracy and loss is 34.78% and 0.975.\n",
      "Generator class accuracy and loss is 97.51% and -0.973.\n",
      "\n",
      "Resnet Accuracy: 0.7215\n",
      "Inception Score: 5.812154703401471\n",
      "Epoch 109:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.62% and 0.647.\n",
      "Discriminator class accuracy and loss on real data is 72.02% and -7.176.\n",
      "Discriminator source accuracy and loss on fake data is 63.24% and 0.637.\n",
      "Discriminator class accuracy and loss on fake data is 97.30% and -0.971.\n",
      "Generator source accuracy and loss is 33.71% and 0.996.\n",
      "Generator class accuracy and loss is 97.17% and -0.969.\n",
      "\n",
      "Resnet Accuracy: 0.6919\n",
      "Inception Score: 4.96795392059126\n",
      "Epoch 110:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.37% and 0.650.\n",
      "Discriminator class accuracy and loss on real data is 72.01% and -7.175.\n",
      "Discriminator source accuracy and loss on fake data is 63.19% and 0.637.\n",
      "Discriminator class accuracy and loss on fake data is 97.60% and -0.974.\n",
      "Generator source accuracy and loss is 33.31% and 0.995.\n",
      "Generator class accuracy and loss is 97.52% and -0.973.\n",
      "\n",
      "Resnet Accuracy: 0.5273\n",
      "Inception Score: 4.732593588786448\n",
      "Epoch 111:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 64.12% and 0.633.\n",
      "Discriminator class accuracy and loss on real data is 72.29% and -7.206.\n",
      "Discriminator source accuracy and loss on fake data is 65.15% and 0.620.\n",
      "Discriminator class accuracy and loss on fake data is 97.31% and -0.970.\n",
      "Generator source accuracy and loss is 33.01% and 1.002.\n",
      "Generator class accuracy and loss is 97.20% and -0.970.\n",
      "\n",
      "Resnet Accuracy: 0.7488\n",
      "Inception Score: 5.260335990163432\n",
      "Epoch 112:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.58% and 0.645.\n",
      "Discriminator class accuracy and loss on real data is 72.45% and -7.219.\n",
      "Discriminator source accuracy and loss on fake data is 63.95% and 0.633.\n",
      "Discriminator class accuracy and loss on fake data is 97.91% and -0.977.\n",
      "Generator source accuracy and loss is 32.74% and 1.009.\n",
      "Generator class accuracy and loss is 97.80% and -0.977.\n",
      "\n",
      "Resnet Accuracy: 0.771\n",
      "Inception Score: 6.237708827408398\n",
      "Epoch 113:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.43% and 0.649.\n",
      "Discriminator class accuracy and loss on real data is 72.72% and -7.239.\n",
      "Discriminator source accuracy and loss on fake data is 64.21% and 0.631.\n",
      "Discriminator class accuracy and loss on fake data is 97.23% and -0.970.\n",
      "Generator source accuracy and loss is 32.58% and 1.009.\n",
      "Generator class accuracy and loss is 97.27% and -0.970.\n",
      "\n",
      "Resnet Accuracy: 0.6664\n",
      "Inception Score: 5.045632178678784\n",
      "Epoch 114:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.27% and 0.653.\n",
      "Discriminator class accuracy and loss on real data is 72.58% and -7.236.\n",
      "Discriminator source accuracy and loss on fake data is 63.18% and 0.639.\n",
      "Discriminator class accuracy and loss on fake data is 97.32% and -0.970.\n",
      "Generator source accuracy and loss is 33.74% and 0.987.\n",
      "Generator class accuracy and loss is 97.31% and -0.970.\n",
      "\n",
      "Resnet Accuracy: 0.6447\n",
      "Inception Score: 5.288125533548714\n",
      "Epoch 115:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.26% and 0.650.\n",
      "Discriminator class accuracy and loss on real data is 72.65% and -7.243.\n",
      "Discriminator source accuracy and loss on fake data is 63.75% and 0.632.\n",
      "Discriminator class accuracy and loss on fake data is 97.46% and -0.973.\n",
      "Generator source accuracy and loss is 32.59% and 1.010.\n",
      "Generator class accuracy and loss is 97.47% and -0.972.\n",
      "\n",
      "Resnet Accuracy: 0.5944\n",
      "Inception Score: 4.5276599512701345\n",
      "Epoch 116:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 63.54% and 0.643.\n",
      "Discriminator class accuracy and loss on real data is 72.99% and -7.275.\n",
      "Discriminator source accuracy and loss on fake data is 64.01% and 0.635.\n",
      "Discriminator class accuracy and loss on fake data is 96.97% and -0.967.\n",
      "Generator source accuracy and loss is 32.34% and 0.992.\n",
      "Generator class accuracy and loss is 96.91% and -0.967.\n",
      "\n",
      "Resnet Accuracy: 0.676\n",
      "Inception Score: 4.687531975404584\n",
      "Epoch 117:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.60% and 0.649.\n",
      "Discriminator class accuracy and loss on real data is 73.09% and -7.277.\n",
      "Discriminator source accuracy and loss on fake data is 63.67% and 0.635.\n",
      "Discriminator class accuracy and loss on fake data is 97.01% and -0.967.\n",
      "Generator source accuracy and loss is 33.10% and 0.989.\n",
      "Generator class accuracy and loss is 96.98% and -0.968.\n",
      "\n",
      "Resnet Accuracy: 0.5261\n",
      "Inception Score: 3.9162242219209844\n",
      "Epoch 118:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 61.85% and 0.657.\n",
      "Discriminator class accuracy and loss on real data is 73.29% and -7.303.\n",
      "Discriminator source accuracy and loss on fake data is 62.76% and 0.644.\n",
      "Discriminator class accuracy and loss on fake data is 97.09% and -0.969.\n",
      "Generator source accuracy and loss is 34.16% and 0.976.\n",
      "Generator class accuracy and loss is 97.09% and -0.969.\n",
      "\n",
      "Resnet Accuracy: 0.9036\n",
      "Inception Score: 7.0729418872124965\n",
      "Epoch 119:\n",
      "Batch Index: 0\n",
      "Batch Index: 100\n",
      "Batch Index: 200\n",
      "Batch Index: 300\n",
      "Batch Index: 400\n",
      "Discriminator source accuracy and loss on real data is 62.75% and 0.645.\n",
      "Discriminator class accuracy and loss on real data is 73.28% and -7.299.\n",
      "Discriminator source accuracy and loss on fake data is 64.64% and 0.626.\n",
      "Discriminator class accuracy and loss on fake data is 96.76% and -0.965.\n",
      "Generator source accuracy and loss is 32.39% and 0.999.\n",
      "Generator class accuracy and loss is 96.71% and -0.965.\n",
      "\n",
      "Resnet Accuracy: 0.5597\n",
      "Inception Score: 5.172511605755813\n"
     ]
    }
   ],
   "source": [
    "max_inception_score = 0\n",
    "for epoch in range(100, 120):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    \n",
    "    d_real_source_accuracies = []\n",
    "    d_real_class_accuracies = []\n",
    "    d_real_source_losses = []\n",
    "    d_real_class_losses = []\n",
    "    d_fake_source_accuracies = []\n",
    "    d_fake_class_accuracies = []\n",
    "    d_fake_source_losses = [] \n",
    "    d_fake_class_losses = []\n",
    "    g_source_accuracies = []\n",
    "    g_class_accuracies = []\n",
    "    g_source_losses = []\n",
    "    g_class_losses = []\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Batch Index: {}\".format(batch_idx))\n",
    "        # Train discriminator with real data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer_d.zero_grad()\n",
    "        sources, classes = discriminator(inputs)\n",
    "        source_targets = torch.ones(sources.shape).to(device)\n",
    "        source_loss = criterion_source(sources, source_targets)\n",
    "        class_loss = 10*criterion_class(classes, targets)\n",
    "        d_real_loss = (source_loss + class_loss)/2\n",
    "        d_real_loss.backward()\n",
    "        # optimizer_d.step()\n",
    "        d_real_source_accuracy = torch.mean((torch.where(sources > 0.5, torch.tensor(1.).to(device), torch.tensor(0.).to(device)) == source_targets).float()).item()*100\n",
    "        d_real_class_accuracy = torch.mean((classes.max(1)[1] == targets).float()).item()*100\n",
    "        d_real_source_accuracies.append(d_real_source_accuracy)\n",
    "        d_real_class_accuracies.append(d_real_class_accuracy)\n",
    "        d_real_source_losses.append(source_loss.item())\n",
    "        d_real_class_losses.append(class_loss.item())\n",
    "        \n",
    "        # Train discriminator with fake data\n",
    "        fake_targets = np.random.randint(0, 10, inputs.shape[0])\n",
    "        gen_input_np = np.c_[np.random.randn(inputs.shape[0], 100), np.eye(10)[fake_targets]]\n",
    "        fake_targets = torch.from_numpy(fake_targets).long().to(device)\n",
    "        gen_input = torch.from_numpy(gen_input_np).float().to(device)\n",
    "        fake_inputs = generator(gen_input)\n",
    "        # optimizer_d.zero_grad()\n",
    "        sources, classes = discriminator(fake_inputs.detach())\n",
    "        source_targets = torch.zeros(sources.shape).to(device)\n",
    "        source_loss = criterion_source(sources, source_targets) \n",
    "        class_loss = criterion_class(classes, fake_targets)\n",
    "        d_fake_loss = (source_loss + class_loss)/2\n",
    "        d_fake_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        d_fake_source_accuracy = np.round(torch.mean((torch.where(sources > 0.5, torch.tensor(1.).to(device), torch.tensor(0.).to(device)) == source_targets).float()).item()*100)\n",
    "        d_fake_class_accuracy = np.round(torch.mean((classes.max(1)[1] == fake_targets).float()).item()*100)\n",
    "        d_fake_source_accuracies.append(d_fake_source_accuracy)\n",
    "        d_fake_class_accuracies.append(d_fake_class_accuracy)\n",
    "        d_fake_source_losses.append(source_loss.item())\n",
    "        d_fake_class_losses.append(class_loss.item())\n",
    "        \n",
    "        # Train generator\n",
    "        optimizer_g.zero_grad()\n",
    "        sources, classes = discriminator(fake_inputs)\n",
    "        source_targets = torch.ones(sources.shape).to(device)\n",
    "        source_loss = criterion_source(sources, source_targets) \n",
    "        class_loss = criterion_class(classes, fake_targets)\n",
    "        g_loss = source_loss + class_loss\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        g_source_accuracy = np.round(torch.mean((torch.where(sources > 0.5, torch.tensor(1.).to(device), torch.tensor(0.).to(device)) == source_targets).float()).item()*100)\n",
    "        g_class_accuracy = np.round(torch.mean((classes.max(1)[1] == fake_targets).float()).item()*100)\n",
    "        g_source_accuracies.append(g_source_accuracy)\n",
    "        g_class_accuracies.append(g_class_accuracy)\n",
    "        g_source_losses.append(source_loss.item())\n",
    "        g_class_losses.append(class_loss.item())\n",
    "\n",
    "    print(\"Discriminator source accuracy and loss on real data is {:.2f}% and {:.3f}.\".format(np.mean(d_real_source_accuracies), np.mean(d_real_source_losses)))\n",
    "    print(\"Discriminator class accuracy and loss on real data is {:.2f}% and {:.3f}.\".format(np.mean(d_real_class_accuracies), np.mean(d_real_class_losses)))\n",
    "    print(\"Discriminator source accuracy and loss on fake data is {:.2f}% and {:.3f}.\".format(np.mean(d_fake_source_accuracies), np.mean(d_fake_source_losses)))\n",
    "    print(\"Discriminator class accuracy and loss on fake data is {:.2f}% and {:.3f}.\".format(np.mean(d_fake_class_accuracies), np.mean(d_fake_class_losses)))\n",
    "    print(\"Generator source accuracy and loss is {:.2f}% and {:.3f}.\".format(np.mean(g_source_accuracies), np.mean(g_source_losses)))\n",
    "    print(\"Generator class accuracy and loss is {:.2f}% and {:.3f}.\\n\".format(np.mean(g_class_accuracies), np.mean(g_class_losses)))\n",
    "\n",
    "    fakes = []\n",
    "    for i in range(100):\n",
    "        fake_targets = np.random.randint(0, 10, 100)\n",
    "        gen_input_np = np.c_[np.random.randn(100, 100), np.eye(10)[fake_targets]]\n",
    "        gen_input = torch.from_numpy(gen_input_np).float().to(device)\n",
    "        fake_inputs = generator(gen_input)\n",
    "        fakes.append((reverse_norm_fake_image(fake_inputs.detach().cpu()), fake_targets))\n",
    "\n",
    "    net.eval()\n",
    "    preds = np.empty((0,10))\n",
    "    all_targets = np.empty((0,100))\n",
    "    for batch_idx, (inputs, targets) in enumerate(fakes):\n",
    "        inputs = nn.functional.upsample(norm_orig_image(inputs), size = 32, mode = \"bilinear\").to(device)\n",
    "        output = net(inputs)\n",
    "        preds = np.r_[preds, output.detach().cpu().numpy()]\n",
    "        all_targets = np.r_[all_targets, targets[None, :]]\n",
    "\n",
    "    inception_score = calculate_inception_score(preds)[0]\n",
    "\n",
    "    print(\"Resnet Accuracy: {}\".format(np.mean(np.argmax(preds, axis = 1) == all_targets.flatten())))\n",
    "    print(\"Inception Score: {}\".format(inception_score))\n",
    "\n",
    "    if inception_score > max_inception_score:\n",
    "        max_inception_score = inception_score\n",
    "        torch.save(generator.state_dict(), \"generator120_large.pt\")\n",
    "        torch.save(discriminator.state_dict(), \"discriminator120_large.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Retrain_Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
